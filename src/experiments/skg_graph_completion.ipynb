{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae495e4-a9ef-4c58-8b20-2cca0144586b",
   "metadata": {},
   "source": [
    "## SKG Graph Completion with Multiple Models\n",
    "\n",
    "### This script trains different graph embedding models for knowledge graph completion tasks\n",
    "### on the SKG dataset and logs all metrics and hyperparameters to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df38927b-d3df-4826-a8ec-ecf833a7fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosa/skg/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.models import (\n",
    "    RotatE, \n",
    "    ComplEx, \n",
    "    TransE, \n",
    "    DistMult, \n",
    "    CrossE, \n",
    "    ConvE,\n",
    "    RESCAL\n",
    ")\n",
    "from pykeen.training import SLCWATrainingLoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257afbde-fb69-4b82-abb6-2b6021fb7a2c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Set up Command Line Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a50a664-4ff3-4516-9a20-a6ee252b4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    import sys\n",
    "    \n",
    "    # Handle running in Jupyter notebook\n",
    "    if any('jupyter' in arg for arg in sys.argv):\n",
    "        # Default arguments when running in notebook\n",
    "        class Args:\n",
    "            dataset = 'gyafc'\n",
    "            output_file = 'results.csv'\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            seed = 42\n",
    "            embedding_dims = [1024] # 128, 256, \n",
    "            learning_rates = [0.0005] # 0.001, \n",
    "            num_epochs = 1000\n",
    "        return Args()\n",
    "    \n",
    "    # Normal argparse for command-line usage\n",
    "    parser = argparse.ArgumentParser(description='Train knowledge graph embedding models on SKG data')\n",
    "    parser.add_argument('--dataset', type=str, default='politeness',\n",
    "                        help='Dataset folder name (e.g., politeness, olid, gyafc)')\n",
    "    parser.add_argument('--output_file', type=str, default='results.csv',\n",
    "                        help='Output CSV file to store results')\n",
    "    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                        help='Device to use for training (cuda or cpu)')\n",
    "    parser.add_argument('--seed', type=int, default=42, \n",
    "                        help='Random seed for reproducibility')\n",
    "    parser.add_argument('--embedding_dims', type=int, nargs='+', default=[128, 256, 512],\n",
    "                        help='Embedding dimensions to try')\n",
    "    parser.add_argument('--learning_rates', type=float, nargs='+', default=[0.001, 0.0005],\n",
    "                        help='Learning rates to try')\n",
    "    parser.add_argument('--num_epochs', type=int, default=50,\n",
    "                        help='Number of training epochs')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f201dd-fa94-4250-8ab2-86c75cce92d2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30328d77-25cf-44f1-80cb-a26fbec0c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataset(dataset_name, create_inverse=False):\n",
    "    \"\"\"\n",
    "    Set up the dataset by loading the triples and splitting into train/valid/test sets.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: Name of the dataset folder\n",
    "        create_inverse: Whether to create inverse triples\n",
    "        \n",
    "    Returns:\n",
    "        train, valid, test factories\n",
    "    \"\"\"\n",
    "    # Get project root (works in both scripts and notebooks)\n",
    "    try:\n",
    "        # For regular Python scripts\n",
    "        project_root = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        # For Jupyter notebooks\n",
    "        import pathlib\n",
    "        project_root = str(pathlib.Path().absolute())\n",
    "    \n",
    "    # Define path to triples file\n",
    "    triples_path = os.path.join(project_root, 'data', 'skg', dataset_name, 'triples.tsv')\n",
    "    \n",
    "    print(f\"Loading triples from: {triples_path}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create triples factory\n",
    "    training_factory = TriplesFactory.from_path(\n",
    "        triples_path, \n",
    "        create_inverse_triples=create_inverse\n",
    "    )\n",
    "    \n",
    "    # Split into train/valid/test\n",
    "    train_factory, valid_factory, test_factory = training_factory.split([0.8, 0.1, 0.1])\n",
    "    \n",
    "    return train_factory, valid_factory, test_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd8d240-ed5a-4634-b43f-f96720fd4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_output_file(output_file):\n",
    "    \"\"\"\n",
    "    Ensure the output CSV file exists with proper headers.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                'timestamp', 'dataset', 'model', 'embedding_dim', 'inverse_triples',\n",
    "                'learning_rate', 'num_epochs', 'batch_size', 'training_time',\n",
    "                'hits@1', 'hits@3', 'hits@10', 'mrr', 'mr'\n",
    "            ])\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b74f692-25c9-40ea-95b3-ee196d07f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(result, config, output_file):\n",
    "    \"\"\"\n",
    "    Log training results to CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            config['dataset'],\n",
    "            config['model_name'],\n",
    "            config['embedding_dim'],\n",
    "            config['inverse_triples'],\n",
    "            config['learning_rate'],\n",
    "            config['num_epochs'],\n",
    "            config['batch_size'],\n",
    "            config['training_time'],\n",
    "            result.metric_results.get_metric('hits_at_1'),\n",
    "            result.metric_results.get_metric('hits_at_3'),\n",
    "            result.metric_results.get_metric('hits_at_10'),\n",
    "            result.metric_results.get_metric('mrr'),\n",
    "            result.metric_results.get_metric('mr')\n",
    "        ])\n",
    "    \n",
    "    # Also print results to console\n",
    "    print(\"\\n=== Results ===\")\n",
    "    print(f\"Model: {config['model_name']}, Dim: {config['embedding_dim']}, LR: {config['learning_rate']}\")\n",
    "    print(f\"Hits@1: {result.metric_results.get_metric('hits_at_1'):.4f}\")\n",
    "    print(f\"Hits@3: {result.metric_results.get_metric('hits_at_3'):.4f}\")\n",
    "    print(f\"Hits@10: {result.metric_results.get_metric('hits_at_10'):.4f}\")\n",
    "    print(f\"MRR: {result.metric_results.get_metric('mrr'):.4f}\")\n",
    "    print(f\"MR: {result.metric_results.get_metric('mr'):.4f}\")\n",
    "    print(f\"Training time: {config['training_time']:.2f} seconds\")\n",
    "    print(\"==============\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b9eaa-17b3-49be-a053-13b4f09b8147",
   "metadata": {},
   "source": [
    "## Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b1ebb2-0cf7-4c2c-b455-4e78ee328b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_class(model_name):\n",
    "    \"\"\"\n",
    "    Get the model class by name.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'RotatE': RotatE,\n",
    "        'ComplEx': ComplEx,\n",
    "        'TransE': TransE,\n",
    "        'DistMult': DistMult,\n",
    "        'CrossE': CrossE,\n",
    "        'ConvE': ConvE,\n",
    "        'RESCAL': RESCAL\n",
    "    }\n",
    "    return models.get(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1270e337-ba1e-4e11-aec4-aca8919a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_factory, valid_factory, test_factory, config):\n",
    "    \"\"\"\n",
    "    Train a single model with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model to train\n",
    "        train_factory: Training triples factory\n",
    "        valid_factory: Validation triples factory\n",
    "        test_factory: Test triples factory\n",
    "        config: Dictionary with configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline result object\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining {model_name} with embedding_dim={config['embedding_dim']}, lr={config['learning_rate']}\")\n",
    "    \n",
    "    # Get model class\n",
    "    model_class = get_model_class(model_name)\n",
    "    \n",
    "    # Create model\n",
    "    model = model_class(\n",
    "        triples_factory=train_factory,\n",
    "        embedding_dim=config['embedding_dim']\n",
    "    )\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = Adam(\n",
    "        params=model.get_grad_params(),\n",
    "        lr=config['learning_rate']\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = SLCWATrainingLoop(\n",
    "        model=model,\n",
    "        triples_factory=train_factory,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    from pykeen.stoppers import EarlyStopper\n",
    "    evaluator = RankBasedEvaluator()\n",
    "\n",
    "\n",
    "    # stopper = EarlyStopper(\n",
    "    #     model=model,\n",
    "    #     evaluation_triples_factory=valid_factory,\n",
    "    #     evaluator=evaluator,\n",
    "    #     evaluation_batch_size=config['batch_size'],\n",
    "    #     frequency=100,  \n",
    "    #     patience=4,  \n",
    "    #     relative_delta=0.01,\n",
    "    #     metric='hits_at_1',\n",
    "    #     training_triples_factory=train_factory,\n",
    "    #     use_tdqm=True,\n",
    "        \n",
    "    # )\n",
    "    \n",
    "    # Run pipeline\n",
    "    result = pipeline(\n",
    "        training=train_factory,\n",
    "        validation=valid_factory,\n",
    "        testing=test_factory,\n",
    "        model=model,\n",
    "        training_loop=trainer,\n",
    "        negative_sampler='basic',\n",
    "        evaluator=evaluator,\n",
    "        # stopper=stopper,\n",
    "        training_kwargs=dict(\n",
    "            num_epochs=config['num_epochs'],\n",
    "            batch_size=config['batch_size'],\n",
    "        ),\n",
    "        evaluator_kwargs=dict(\n",
    "            batch_size=config['batch_size'],\n",
    "        ),\n",
    "        device=config['device'],\n",
    "        random_seed=config['seed'],\n",
    "    )\n",
    "\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    config['training_time'] = training_time\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f12f9-e567-4383-8c3e-483206e25726",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b42fcf-d124-4357-bc2b-4c67846c556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = parse_arguments()\n",
    "    \n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "    output_file = ensure_output_file(args.output_file)\n",
    "    \n",
    "    models = ['RotatE' ] #  'ComplEx', 'TransE', 'DistMult'\n",
    "    \n",
    "    inverse_triples_models = ['CrossE', 'TransE']\n",
    "    \n",
    "    # Loop over models\n",
    "    for model_name in models:\n",
    "        # Determine if this model should use inverse triples\n",
    "        use_inverse = model_name in inverse_triples_models\n",
    "        \n",
    "        # Set up dataset\n",
    "        train_factory, valid_factory, test_factory = setup_dataset(\n",
    "            args.dataset, \n",
    "            create_inverse=use_inverse\n",
    "        )\n",
    "        \n",
    "        for embedding_dim in args.embedding_dims:\n",
    "            for lr in args.learning_rates:\n",
    "                config = {\n",
    "                    'model_name': model_name,\n",
    "                    'dataset': args.dataset,\n",
    "                    'embedding_dim': embedding_dim,\n",
    "                    'learning_rate': lr,\n",
    "                    'num_epochs': args.num_epochs,\n",
    "                    'batch_size': 2048,\n",
    "                    'device': args.device,\n",
    "                    'inverse_triples': use_inverse,\n",
    "                    'seed': args.seed,\n",
    "                }\n",
    "                \n",
    "                result = train_model(\n",
    "                    model_name,\n",
    "                    train_factory,\n",
    "                    valid_factory,\n",
    "                    test_factory,\n",
    "                    config\n",
    "                )\n",
    "                \n",
    "                log_results(result, config, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf2a6b3-0ddf-4c85-9ce2-2452be6894cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triples from: /home/bosa/skg/data/skg/gyafc/triples.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=275319731\n",
      "No random seed is specified. This may lead to non-reproducible results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RotatE with embedding_dim=1024, lr=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0: 100%|██████████| 1000/1000 [47:42<00:00,  2.86s/epoch, loss=0.00118, prev_loss=0.00118]\n",
      "Evaluating on cuda:0: 100%|██████████| 19.2k/19.2k [21:00<00:00, 15.3triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1272.80s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n",
      "Model: RotatE, Dim: 1024, LR: 0.0005\n",
      "Hits@1: 0.2567\n",
      "Hits@3: 0.3849\n",
      "Hits@10: 0.4909\n",
      "MRR: 0.3398\n",
      "MR: 3590.3472\n",
      "Training time: 4136.65 seconds\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
